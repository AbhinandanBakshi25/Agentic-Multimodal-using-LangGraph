# -*- coding: utf-8 -*-
"""Agentic Multimodal using LangGraph.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1I6RAU8h5GdEwTNc-xl9DnLJx2gs02D7l
"""

!pip install langgraph pymupdf pillow

from typing import TypedDict, Optional
from PIL import Image
import fitz  # PyMuPDF

class AgentState(TypedDict):
    query: str
    image: Image.Image
    result: Optional[str]
    final_decision: Optional[str]

def planner_agent(query: str) -> str:
    # In real systems this can decompose tasks
    return query

def vision_agent(image: Image.Image, query: str) -> str:
    # Placeholder for SIGLIP / vision model
    return "The document page appears clean, readable, and professionally structured."

def vision_agent(image: Image.Image, query: str) -> str:
    # Placeholder for SIGLIP / vision model
    return "The document page appears clean, readable, and professionally structured."

def decision_agent(state: AgentState) -> AgentState:
    return {
        **state,
        "final_decision": f"Final Verdict: {state['result']}"
    }

from langgraph.graph import StateGraph, END

def build_agent_graph():
    graph = StateGraph(AgentState)

    graph.add_node(
        "planner",
        lambda state: {
            **state,
            "query": planner_agent(state["query"])
        }
    )

    graph.add_node(
        "vision",
        lambda state: {
            **state,
            "result": vision_agent(state["image"], state["query"])
        }
    )

    graph.add_node("decision", decision_agent)

    graph.set_entry_point("planner")
    graph.add_edge("planner", "vision")
    graph.add_edge("vision", "decision")
    graph.add_edge("decision", END)

    return graph.compile()

agent = build_agent_graph()

from google.colab import files

uploaded = files.upload()
pdf_path = list(uploaded.keys())[0]

doc = fitz.open(pdf_path)

query = "Is this document suitable for a professional resume?"

results = []

for page_number, page in enumerate(doc):
    pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
    img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)

    output = agent.invoke({
        "query": query,
        "image": img,
        "result": None,
        "final_decision": None
    })

    results.append({
        "page": page_number + 1,
        "analysis": output["final_decision"]
    })

results

